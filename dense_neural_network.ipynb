{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "dense_neural_network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEsUxk_Lm4Nl"
      },
      "source": [
        "## Author Identification with Fully Connected Neural Network\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPUoR28Tm4zF"
      },
      "source": [
        "### Imports and Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4cYv7iGL70K",
        "outputId": "157bc4cb-cedd-4972-d7ac-b518cc1d6382"
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow.random import set_seed\n",
        "set_seed(2)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "from keras.layers import Layer\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from gensim.test.utils import common_texts\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import pickle\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "#np.random.seed(1)\n",
        "random_state = 7"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZDZEeviL-Bp",
        "outputId": "989aebd2-8389-4c9e-fcb5-ea392e065828"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdXzzP66mRNo"
      },
      "source": [
        "Reading only the train set of the data since the test set doesn't have labels and we ended up not using it at all."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "GY_GOKilL_h7",
        "outputId": "a674639b-42a5-4a3c-fb35-232184aabc38"
      },
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/Author_identification/train.csv') \n",
        "train.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id26305</td>\n",
              "      <td>This process, however, afforded me no means of...</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id17569</td>\n",
              "      <td>It never once occurred to me that the fumbling...</td>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id11008</td>\n",
              "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id27763</td>\n",
              "      <td>How lovely is spring As we looked from Windsor...</td>\n",
              "      <td>MWS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id12958</td>\n",
              "      <td>Finding nothing else, not even gold, the Super...</td>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                               text author\n",
              "0  id26305  This process, however, afforded me no means of...    EAP\n",
              "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
              "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
              "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
              "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thQtUekFmagf"
      },
      "source": [
        "Executing the neccessary data preparation steps on each entry of the data (punctuation removal, lowercase letters, redefining the labels as numbers)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0pxgbPuMPqf"
      },
      "source": [
        "author_dict = {'EAP': 0, 'HPL': 1, 'MWS': 2}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQhh68p2MTOJ"
      },
      "source": [
        "new_text = []\n",
        "new_author = []\n",
        "for i, row in train[['text','author']].iterrows():\n",
        "  word_tokens = word_tokenize(row['text'])\n",
        "  new_text.append((\" \".join([w for w in word_tokens if not w in [',','.','?','!',':',';',\"'\",'\"','-',\"''\",'``']]).lower())) # left the stopwords in, as it gave better results\n",
        "  new_author.append(author_dict[row['author']])\n",
        "new_train = pd.DataFrame(data={'text': new_text, 'author': new_author})"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ucX1DFgMWuJ"
      },
      "source": [
        "X = new_train['text']\n",
        "y = new_train['author']\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=random_state)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJlYcslBMeph"
      },
      "source": [
        "X_train_list = list(X_train)\n",
        "y_train_list = list(y_train)\n",
        "X_valid_list = list(X_valid)\n",
        "y_valid_list = list(y_valid)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNXyvrKHXl8t"
      },
      "source": [
        "y_train_list = np.array(y_train_list)\n",
        "y_valid_list = np.array(y_valid_list)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UIHE1aSM4sU"
      },
      "source": [
        "### Pre-trained fastText vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MOZbx-sOvJQ"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/Author_identification/fasttext_vectors.pickle\", 'rb') as f:\n",
        "    fasttext_vectors = pickle.load(f) #we had this downloaded, below is the code to get this file for the first time"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owaw8Uo5p4-i"
      },
      "source": [
        "#import gensim.downloader\r\n",
        "#fasttext_vectors = gensim.downloader.load('fasttext-wiki-news-subwords-300') # roughly 1 GB file"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8SLICyW0OKd"
      },
      "source": [
        "#### Using the mean of the wordvectors in each entry to get a single vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXHEQpFmM2_V",
        "outputId": "ab49bf47-cf54-4c6b-bc48-3aa075adc8b1"
      },
      "source": [
        "X_train_mean_vectors = np.empty([len(X_train_list), 300])\n",
        "for j in range(len(X_train_list)):\n",
        "  X_train_vectors = np.empty([len(X_train_list[j].split()), 300])\n",
        "  for i in range(len(X_train_list[j].split())):\n",
        "    try:\n",
        "      X_train_vectors[i] = fasttext_vectors.wv[X_train_list[j].split()[i]]\n",
        "    except KeyError:\n",
        "      X_train_vectors[i] = np.zeros(300)\n",
        "  X_train_mean_vectors[j] = np.mean(X_train_vectors, axis=0)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOGjHm0jy5EV"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_mean_vectors = scaler.fit_transform(X_train_mean_vectors)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HC4F00NM0Sad",
        "outputId": "9cce37ce-d26d-430b-8a69-690b3a15b192"
      },
      "source": [
        "X_valid_mean_vectors = np.empty([len(X_valid_list), 300])\n",
        "for j in range(len(X_valid_list)):\n",
        "  X_valid_vectors = np.empty([len(X_valid_list[j].split()), 300])\n",
        "  for i in range(len(X_valid_list[j].split())):\n",
        "    try:\n",
        "      X_valid_vectors[i] = fasttext_vectors.wv[X_valid_list[j].split()[i]]\n",
        "    except KeyError:\n",
        "      X_valid_vectors[i] = np.zeros(300)\n",
        "  X_valid_mean_vectors[j] = np.mean(X_valid_vectors, axis=0)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPCR5XmZ0SuX"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "X_valid_mean_vectors = scaler.fit_transform(X_valid_mean_vectors)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URsWRR6QncXt"
      },
      "source": [
        "### The model itself and training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GXqbkjvi5ZX"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "y_train_list = to_categorical(y_train_list) # one-hot encoding the labels\n",
        "y_valid_list = to_categorical(y_valid_list)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mic7KI7PT3mz",
        "outputId": "e073ab09-d0a6-42d5-c093-d37fdcaf44d8"
      },
      "source": [
        "dense_model = tf.keras.models.Sequential()\n",
        "dense_model.add(tf.keras.Input(shape=(300,)))\n",
        "dense_model.add(tf.keras.layers.Dense(300, activation='relu', kernel_initializer='he_normal'))\n",
        "dense_model.add(Dropout(0.4))\n",
        "dense_model.add(tf.keras.layers.Dense(300, activation='relu', kernel_initializer='he_normal'))\n",
        "dense_model.add(tf.keras.layers.Dense(300, activation='relu', kernel_initializer='he_normal'))\n",
        "dense_model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "dense_model.output_shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH-iIvnBZcY9"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "early_stopping=EarlyStopping(monitor=\"val_accuracy\",patience=10, verbose=1)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpGYmq74VvO7"
      },
      "source": [
        "dense_model.compile(optimizer=Adam(lr=1e-3),loss='categorical_crossentropy' ,metrics=['accuracy'])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S42erVs6V40m",
        "outputId": "927dec32-f65b-4c3e-fb13-cc27198a5e7c"
      },
      "source": [
        "result = dense_model.fit(X_train_mean_vectors, y_train_list,  validation_data = (X_valid_mean_vectors, y_valid_list),\n",
        "                     callbacks=[early_stopping], epochs=75)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.8969 - accuracy: 0.6150 - val_loss: 0.7057 - val_accuracy: 0.7084\n",
            "Epoch 2/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.7177 - accuracy: 0.6985 - val_loss: 0.6835 - val_accuracy: 0.7188\n",
            "Epoch 3/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.6505 - accuracy: 0.7315 - val_loss: 0.6514 - val_accuracy: 0.7351\n",
            "Epoch 4/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.6156 - accuracy: 0.7457 - val_loss: 0.6548 - val_accuracy: 0.7319\n",
            "Epoch 5/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.5846 - accuracy: 0.7583 - val_loss: 0.6586 - val_accuracy: 0.7276\n",
            "Epoch 6/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.5623 - accuracy: 0.7685 - val_loss: 0.6197 - val_accuracy: 0.7484\n",
            "Epoch 7/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.5362 - accuracy: 0.7820 - val_loss: 0.6231 - val_accuracy: 0.7463\n",
            "Epoch 8/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.5130 - accuracy: 0.7942 - val_loss: 0.6117 - val_accuracy: 0.7472\n",
            "Epoch 9/75\n",
            "429/429 [==============================] - 2s 4ms/step - loss: 0.4938 - accuracy: 0.7970 - val_loss: 0.6264 - val_accuracy: 0.7506\n",
            "Epoch 10/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.4693 - accuracy: 0.8084 - val_loss: 0.6347 - val_accuracy: 0.7492\n",
            "Epoch 11/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.4570 - accuracy: 0.8148 - val_loss: 0.6362 - val_accuracy: 0.7470\n",
            "Epoch 12/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.4282 - accuracy: 0.8252 - val_loss: 0.6342 - val_accuracy: 0.7520\n",
            "Epoch 13/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.4132 - accuracy: 0.8336 - val_loss: 0.6539 - val_accuracy: 0.7554\n",
            "Epoch 14/75\n",
            "429/429 [==============================] - 2s 4ms/step - loss: 0.3957 - accuracy: 0.8416 - val_loss: 0.6529 - val_accuracy: 0.7503\n",
            "Epoch 15/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.3794 - accuracy: 0.8470 - val_loss: 0.6515 - val_accuracy: 0.7469\n",
            "Epoch 16/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.3658 - accuracy: 0.8524 - val_loss: 0.6563 - val_accuracy: 0.7564\n",
            "Epoch 17/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.3513 - accuracy: 0.8593 - val_loss: 0.6923 - val_accuracy: 0.7392\n",
            "Epoch 18/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.3374 - accuracy: 0.8615 - val_loss: 0.6856 - val_accuracy: 0.7494\n",
            "Epoch 19/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.3311 - accuracy: 0.8664 - val_loss: 0.7029 - val_accuracy: 0.7465\n",
            "Epoch 20/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.3151 - accuracy: 0.8747 - val_loss: 0.6910 - val_accuracy: 0.7494\n",
            "Epoch 21/75\n",
            "429/429 [==============================] - 2s 4ms/step - loss: 0.3049 - accuracy: 0.8773 - val_loss: 0.7143 - val_accuracy: 0.7491\n",
            "Epoch 22/75\n",
            "429/429 [==============================] - 2s 4ms/step - loss: 0.2935 - accuracy: 0.8838 - val_loss: 0.6914 - val_accuracy: 0.7489\n",
            "Epoch 23/75\n",
            "429/429 [==============================] - 2s 4ms/step - loss: 0.2959 - accuracy: 0.8841 - val_loss: 0.7672 - val_accuracy: 0.7404\n",
            "Epoch 24/75\n",
            "429/429 [==============================] - 2s 4ms/step - loss: 0.2710 - accuracy: 0.8974 - val_loss: 0.7551 - val_accuracy: 0.7482\n",
            "Epoch 25/75\n",
            "429/429 [==============================] - 2s 4ms/step - loss: 0.2746 - accuracy: 0.8924 - val_loss: 0.7489 - val_accuracy: 0.7504\n",
            "Epoch 26/75\n",
            "429/429 [==============================] - 2s 4ms/step - loss: 0.2597 - accuracy: 0.8972 - val_loss: 0.8100 - val_accuracy: 0.7513\n",
            "Epoch 00026: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIwh4bxUJQWC",
        "outputId": "e0b8caa8-1463-4282-a1aa-ba98c6795696"
      },
      "source": [
        "best_val_acc = np.amax(result.history['val_accuracy']) \n",
        "print('legjobb val_accuracy:', best_val_acc)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "legjobb val_accuracy: 0.7563840746879578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1QM3GsvXEva",
        "outputId": "8dd3e4f0-142d-4ba8-d4f8-1f089e5db4dd"
      },
      "source": [
        "score = dense_model.evaluate(X_valid_mean_vectors, y_valid_list, verbose = 0)\n",
        "print(\"Test score: \", score[0])\n",
        "print(\"Test accuracy: \", score[1])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score:  0.8099644184112549\n",
            "Test accuracy:  0.7512767910957336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ihKtmwSnf_a"
      },
      "source": [
        "The most important codes were already shown at this point, going forward there are a few methods we tried with this model but eventually proved to be less accurate or didn't work to the extent we would have liked it to."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAoRSyMz6neV"
      },
      "source": [
        "### Creating the word embeddings using minmax vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XE7pt-LK6oDc",
        "outputId": "4b02f960-7634-42d2-f4ba-bd70b6e3eef2"
      },
      "source": [
        "X_train_min_vectors = np.empty([len(X_train_list), 300])\r\n",
        "for j in range(len(X_train_list)):\r\n",
        "  X_train_vectors = np.empty([len(X_train_list[j].split()), 300])\r\n",
        "  for i in range(len(X_train_list[j].split())):\r\n",
        "    try:\r\n",
        "      X_train_vectors[i] = fasttext_vectors.wv[X_train_list[j].split()[i]]\r\n",
        "    except KeyError:\r\n",
        "      X_train_vectors[i] = np.zeros(300)\r\n",
        "  X_train_min_vectors[j] = X_train_vectors.min(axis=0)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xN2U1e7x6oLX",
        "outputId": "a85f25ee-fb8a-44f3-8484-dd4485d2b7e1"
      },
      "source": [
        "X_train_max_vectors = np.empty([len(X_train_list), 300])\r\n",
        "for j in range(len(X_train_list)):\r\n",
        "  X_train_vectors = np.empty([len(X_train_list[j].split()), 300])\r\n",
        "  for i in range(len(X_train_list[j].split())):\r\n",
        "    try:\r\n",
        "      X_train_vectors[i] = fasttext_vectors.wv[X_train_list[j].split()[i]]\r\n",
        "    except KeyError:\r\n",
        "      X_train_vectors[i] = np.zeros(300)\r\n",
        "  X_train_max_vectors[j] = X_train_vectors.max(axis=0)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsVTaI9t6oSB"
      },
      "source": [
        "X_train_minmax_vectors = np.concatenate((X_train_min_vectors, X_train_max_vectors), axis=1)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQMRk9Gu6oVP"
      },
      "source": [
        "scaler = StandardScaler()\r\n",
        "X_train_minmax_vectors = scaler.fit_transform(X_train_minmax_vectors)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeQmwCMP7Wrd"
      },
      "source": [
        "On the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBfYVlz87QK8",
        "outputId": "f4d99994-ea1d-4553-facb-6fdf7e3f6c79"
      },
      "source": [
        "X_valid_min_vectors = np.empty([len(X_valid_list), 300])\r\n",
        "for j in range(len(X_valid_list)):\r\n",
        "  X_valid_vectors = np.empty([len(X_valid_list[j].split()), 300])\r\n",
        "  for i in range(len(X_valid_list[j].split())):\r\n",
        "    try:\r\n",
        "      X_valid_vectors[i] = fasttext_vectors.wv[X_valid_list[j].split()[i]]\r\n",
        "    except KeyError:\r\n",
        "      X_valid_vectors[i] = np.zeros(300)\r\n",
        "  X_valid_min_vectors[j] = X_valid_vectors.min(axis=0)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzBqaOZ67P79",
        "outputId": "665b83df-4330-4cb6-abb9-6afbb0cd2fa4"
      },
      "source": [
        "X_valid_max_vectors = np.empty([len(X_valid_list), 300])\r\n",
        "for j in range(len(X_valid_list)):\r\n",
        "  X_valid_vectors = np.empty([len(X_valid_list[j].split()), 300])\r\n",
        "  for i in range(len(X_valid_list[j].split())):\r\n",
        "    try:\r\n",
        "      X_valid_vectors[i] = fasttext_vectors.wv[X_valid_list[j].split()[i]]\r\n",
        "    except KeyError:\r\n",
        "      X_valid_vectors[i] = np.zeros(300)\r\n",
        "  X_valid_max_vectors[j] = X_valid_vectors.min(axis=0)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ksl-JaZR7P1S"
      },
      "source": [
        "X_valid_minmax_vectors = np.concatenate((X_valid_min_vectors, X_valid_max_vectors), axis=1)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS1xnAHy7Ppz"
      },
      "source": [
        "scaler = StandardScaler()\r\n",
        "X_valid_minmax_vectors = scaler.fit_transform(X_valid_minmax_vectors)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBA0HbD785w7",
        "outputId": "1477c65f-ff97-4e8a-93d9-f30d62c88959"
      },
      "source": [
        "dense_model_mm = tf.keras.models.Sequential()\r\n",
        "dense_model_mm.add(tf.keras.Input(shape=(600,)))\r\n",
        "dense_model_mm.add(tf.keras.layers.Dense(300, activation='relu', kernel_initializer='he_normal'))\r\n",
        "dense_model_mm.add(tf.keras.layers.Dense(300, activation='relu', kernel_initializer='he_normal'))\r\n",
        "dense_model_mm.add(tf.keras.layers.Dense(300, activation='relu', kernel_initializer='he_normal'))\r\n",
        "dense_model_mm.add(tf.keras.layers.Dense(3, activation='softmax'))\r\n",
        "dense_model_mm.output_shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpC_lxA085q4"
      },
      "source": [
        "dense_model_mm.compile(optimizer=Adam(lr=1e-5),loss='categorical_crossentropy' ,metrics=['accuracy'])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsLn_9uX85lq",
        "outputId": "c01ab764-9348-4bd8-f834-12b2146ce942"
      },
      "source": [
        "dense_model_mm.fit(X_train_minmax_vectors, y_train_list,  validation_data = (X_valid_minmax_vectors, y_valid_list),\r\n",
        "                     callbacks=[early_stopping], epochs=75)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "429/429 [==============================] - 2s 4ms/step - loss: 1.2108 - accuracy: 0.3807 - val_loss: 1.1883 - val_accuracy: 0.3805\n",
            "Epoch 2/75\n",
            "429/429 [==============================] - 2s 4ms/step - loss: 1.0709 - accuracy: 0.4611 - val_loss: 1.1387 - val_accuracy: 0.4076\n",
            "Epoch 3/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.9974 - accuracy: 0.5090 - val_loss: 1.1077 - val_accuracy: 0.4305\n",
            "Epoch 4/75\n",
            "429/429 [==============================] - 2s 4ms/step - loss: 0.9465 - accuracy: 0.5425 - val_loss: 1.0984 - val_accuracy: 0.4419\n",
            "Epoch 5/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.9061 - accuracy: 0.5749 - val_loss: 1.0783 - val_accuracy: 0.4564\n",
            "Epoch 6/75\n",
            "429/429 [==============================] - 2s 4ms/step - loss: 0.8727 - accuracy: 0.5994 - val_loss: 1.0793 - val_accuracy: 0.4608\n",
            "Epoch 7/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.8437 - accuracy: 0.6192 - val_loss: 1.0706 - val_accuracy: 0.4694\n",
            "Epoch 8/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.8178 - accuracy: 0.6352 - val_loss: 1.0771 - val_accuracy: 0.4736\n",
            "Epoch 9/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.7944 - accuracy: 0.6495 - val_loss: 1.0705 - val_accuracy: 0.4796\n",
            "Epoch 10/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.7731 - accuracy: 0.6614 - val_loss: 1.0816 - val_accuracy: 0.4791\n",
            "Epoch 11/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.7532 - accuracy: 0.6735 - val_loss: 1.0830 - val_accuracy: 0.4792\n",
            "Epoch 12/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.7345 - accuracy: 0.6839 - val_loss: 1.0832 - val_accuracy: 0.4837\n",
            "Epoch 13/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.7171 - accuracy: 0.6976 - val_loss: 1.0883 - val_accuracy: 0.4848\n",
            "Epoch 14/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.7006 - accuracy: 0.7047 - val_loss: 1.0956 - val_accuracy: 0.4860\n",
            "Epoch 15/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.6849 - accuracy: 0.7116 - val_loss: 1.0995 - val_accuracy: 0.4852\n",
            "Epoch 16/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.6702 - accuracy: 0.7206 - val_loss: 1.0962 - val_accuracy: 0.4918\n",
            "Epoch 17/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.6558 - accuracy: 0.7279 - val_loss: 1.1077 - val_accuracy: 0.4896\n",
            "Epoch 18/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.6422 - accuracy: 0.7338 - val_loss: 1.1150 - val_accuracy: 0.4874\n",
            "Epoch 19/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.6290 - accuracy: 0.7418 - val_loss: 1.1204 - val_accuracy: 0.4883\n",
            "Epoch 20/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.6161 - accuracy: 0.7488 - val_loss: 1.1290 - val_accuracy: 0.4884\n",
            "Epoch 21/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.6037 - accuracy: 0.7570 - val_loss: 1.1252 - val_accuracy: 0.4893\n",
            "Epoch 22/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.5915 - accuracy: 0.7629 - val_loss: 1.1279 - val_accuracy: 0.4901\n",
            "Epoch 23/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.5796 - accuracy: 0.7696 - val_loss: 1.1471 - val_accuracy: 0.4900\n",
            "Epoch 24/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.5683 - accuracy: 0.7743 - val_loss: 1.1450 - val_accuracy: 0.4898\n",
            "Epoch 25/75\n",
            "429/429 [==============================] - 1s 3ms/step - loss: 0.5569 - accuracy: 0.7802 - val_loss: 1.1424 - val_accuracy: 0.4901\n",
            "Epoch 26/75\n",
            "429/429 [==============================] - 2s 4ms/step - loss: 0.5460 - accuracy: 0.7867 - val_loss: 1.1521 - val_accuracy: 0.4900\n",
            "Epoch 00026: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fce49fbfac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9pMSqMx85gh",
        "outputId": "21f2c2a8-d27c-4463-b55c-4ef118c94b63"
      },
      "source": [
        "score = dense_model_mm.evaluate(X_valid_minmax_vectors, y_valid_list, verbose = 0)\r\n",
        "print(\"Test score: \", score[0])\r\n",
        "print(\"Test accuracy: \", score[1])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score:  1.1520824432373047\n",
            "Test accuracy:  0.48995572328567505\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyiAs-_s-BrR"
      },
      "source": [
        "The results are way worse interestingly than the mean vector method, even though these two are often recommended as similar solutions for the same problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m505qFapgCo"
      },
      "source": [
        "### Applying the model for prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkBqNO-Zqjfn"
      },
      "source": [
        "Here the model is supposed to read in any sentence and give a prediction for probabilities of the author."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_Tq2FjNppNq"
      },
      "source": [
        "den_model = tf.keras.models.load_model('/content/drive/MyDrive/Author_identification/author_identification_dense_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQM5pbbOqQPi"
      },
      "source": [
        "reverse_author_dict = {0: 'Edgar Allan Poe', 1: 'HP Lovecraft', 2: 'Mary Shelley'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwTuqy2Jl1tU"
      },
      "source": [
        "In the following function we first do the same data manipulation steps as before the actual training. Then predict an author from that input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Et2yNB8q6mi"
      },
      "source": [
        "def who_wrote(sentence):\r\n",
        "  word_tokens = word_tokenize(sentence)\r\n",
        "  sentence_tok = ((\" \".join([w for w in word_tokens if not w in [',','.','?','!',':',';',\"'\",'\"','-',\"''\",'``']]).lower()))\r\n",
        "  mean_vector = np.empty(300)\r\n",
        "  ft_vectors = np.empty([len(sentence_tok.split()), 300])\r\n",
        "  for i in range(len(sentence_tok.split())):\r\n",
        "    try:\r\n",
        "      ft_vectors[i] = fasttext_vectors.wv[sentence_tok.split()[i]]\r\n",
        "    except KeyError:\r\n",
        "      ft_vectors[i] = np.zeros(300)\r\n",
        "  mean_vector = np.mean(ft_vectors, axis=0)\r\n",
        "  mean_vector = mean_vector.reshape(1, -1)\r\n",
        "  #scaler = StandardScaler()\r\n",
        "  #mean_vector = scaler.fit_transform(mean_vector)\r\n",
        "  result = den_model.predict(mean_vector)\r\n",
        "  print(', '.join([reverse_author_dict[i] + ': ' + str(round(result[0][i] * 100,2)) + '%' for i in range(3)]))\r\n",
        "  print('Result: ', reverse_author_dict[np.argmax(result)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEm7K4BIrG0Z"
      },
      "source": [
        "who_wrote('If a fire wanted fanning, it could readily be fanned with a newspaper.') #this is a sentence from Edgar Allen Poe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6l3yih3rp1d"
      },
      "source": [
        "who_wrote('What though their hireling Greaser bands') #this is from HP Lovecraft"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ED6JtVM2s6Lb"
      },
      "source": [
        "Here there was an error somewhere definitely since the model shouldn't predict pretty much the same percentages for every sentence and we couldn't find a fix for this before the deadline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MSj_skvtR72"
      },
      "source": [
        "who_wrote('Cthulhu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2knegO4cm2zX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}